{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e235e71b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Compute the relationship DAG of motivation, emotion and action given a piece of text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae484bc7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03b039",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "from mlconjug3 import Conjugator\n",
    "\n",
    "from blink_v3 import Engine\n",
    "from belief import Belief\n",
    "import render\n",
    "from utils import get_verb_forms,clean_sent\n",
    "from config import belief_setting, aser_setting, personal_pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f455fdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from aser.client import ASERClient # check aser website for installing and setting up client\n",
    "client = ASERClient(port=8000, port_out=8001)\n",
    "\n",
    "conjugator = Conjugator(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a45e3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_text='''\n",
    "\n",
    "I am quite happy with the taste of these dried lima beans  also known as  butter beans  in some circles. These beans come in plastic bags that have a re-sealable zip-lock top. The beans that I have used re-hydrated perfectly and had a good flavor.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2fde2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract Events by ASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5cf6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.Extract Events by ASER\n",
    "\n",
    "# split review_text into sentences\n",
    "text_s = re.split('[.!\\?]', input_text)\n",
    "# pop '' out and remove heading whitespace in sentence\n",
    "text_s_new=[]\n",
    "for s in text_s:\n",
    "    if s=='':\n",
    "        continue\n",
    "    text_s_new.append(s.strip())\n",
    "# get eventualities by ASER\n",
    "s_list=[] # list of str\n",
    "aser_list=[] # list of list of corresponding aser_event\n",
    "for s in text_s_new:\n",
    "    try:\n",
    "        events = client.extract_eventualities(s)\n",
    "    except:\n",
    "        events = [[]]\n",
    "    if isinstance(events,list):\n",
    "        s_list.append(s)\n",
    "        aser_list.append(events[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266121f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305053d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "aser_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a060ff4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Restore Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cc7bd",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 3.Restore Events\n",
    "\n",
    "text_id=-1\n",
    "\n",
    "sentences= s_list\n",
    "\n",
    "aser= aser_list\n",
    "\n",
    "event_sent_list=[]\n",
    "for s,event_list in zip(sentences,aser):\n",
    "    for e in event_list:\n",
    "        event_sent_list.append((text_id,e,s))\n",
    "        \n",
    "# get all verbs from events\n",
    "verbs=set()\n",
    "\n",
    "for text_id,event, sent in tqdm.tqdm(event_sent_list):\n",
    "\n",
    "    for w, pt in zip(event.__repr__().split(' '),event.pos_tags):\n",
    "\n",
    "        if 'VB' in pt:\n",
    "\n",
    "            verbs.add(w)\n",
    "\n",
    "verbs=list(verbs)\n",
    "print(\"Total verbs: %d\"%len(verbs))\n",
    "\n",
    "verb_tense={}\n",
    "fail=[]\n",
    "for v in tqdm.tqdm(verbs):\n",
    "    tmp,status=get_verb_forms(conjugator,v)\n",
    "    if status==-1:\n",
    "        fail.append(v)\n",
    "    else:\n",
    "        verb_tense[v]=tmp\n",
    "print(\"Failing verbs: %d\"%len(fail))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a39f3",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# update: process ;:\n",
    "\n",
    "event_processed=[] # (text_id, event, raw_event_text, sub_sent, sent)\n",
    "event_unprocessed=[] # (text_id, event,'', '', sent)\n",
    "\n",
    "for text_id, event, sent in tqdm.tqdm(event_sent_list):\n",
    "    event_text=event.__repr__()\n",
    "    hw=event_text.split(' ')[0]\n",
    "    hw_pos=event.pos_tags[0]\n",
    "    tw=event_text.split(' ')[-1]\n",
    "    tw_pos=event.pos_tags[-1]\n",
    "\n",
    "    sub_sents=re.split('\\.|,', clean_sent(sent))\n",
    "\n",
    "    match_res=[]\n",
    "\n",
    "    for ss in sub_sents:\n",
    "        ss_cut=ss.split(' ')\n",
    "\n",
    "        start_inds=set()\n",
    "        end_inds=set()\n",
    "\n",
    "        for i,sw in enumerate(ss_cut):\n",
    "            sw=sw.lower()\n",
    "\n",
    "            # (1) head word and tail word matching\n",
    "            if sw==hw:\n",
    "                start_ind=i\n",
    "                start_inds.add(start_ind)\n",
    "            if sw==tw:\n",
    "                end_ind=i\n",
    "                end_inds.add(end_ind)\n",
    "            # (2) upper/lower case matching       \n",
    "            # if sw.lower()==hw:\n",
    "            #     start_ind=i\n",
    "            #     start_inds.add(start_ind)\n",
    "\n",
    "            # if sw.lower()==tw:\n",
    "            #     end_ind=i\n",
    "            #     end_inds.add(end_ind)\n",
    "\n",
    "            # (3) plural matching\n",
    "            if 'NN' in hw_pos:\n",
    "                blob = TextBlob(hw)\n",
    "                tmp=[word.pluralize() for word in blob.words]\n",
    "                hw_plural = tmp[0] if len(tmp)>0 else ''\n",
    "                if sw==hw_plural:\n",
    "                    start_ind=i\n",
    "                    start_inds.add(start_ind)\n",
    "\n",
    "            if 'NN' in tw_pos:\n",
    "                blob = TextBlob(tw)\n",
    "                tmp=[word.pluralize() for word in blob.words]\n",
    "                tw_plural = tmp[0] if len(tmp)>0 else ''\n",
    "                if sw==tw_plural:\n",
    "                    end_ind=i\n",
    "                    end_inds.add(end_ind)\n",
    "\n",
    "            # (4) verb-tense matching\n",
    "            if 'VB' in hw_pos and hw in verb_tense:\n",
    "                tmp=verb_tense[hw]\n",
    "                for t in tmp:\n",
    "                    if sw==t:\n",
    "                        start_ind=i\n",
    "                        start_inds.add(start_ind)\n",
    "\n",
    "            if 'VB' in tw_pos and tw in verb_tense:\n",
    "                tmp=verb_tense[tw]\n",
    "                for t in tmp:\n",
    "                    if sw==t:\n",
    "                        end_ind=i\n",
    "                        end_inds.add(end_ind)\n",
    "\n",
    "            # (5) personal pronoun matching\n",
    "            if hw in personal_pronoun:\n",
    "                tmp=personal_pronoun[hw]\n",
    "                for t in tmp:\n",
    "                    if sw==t:\n",
    "                        start_ind=i\n",
    "                        start_inds.add(start_ind)\n",
    "\n",
    "            if tw in personal_pronoun:\n",
    "                tmp=personal_pronoun[tw]\n",
    "                for t in tmp:\n",
    "                    if sw==t:\n",
    "                        end_ind=i\n",
    "                        end_inds.add(end_ind)\n",
    "\n",
    "        \n",
    "        match_res.append((ss_cut, start_inds, end_inds))\n",
    "\n",
    "    # determine the final start and end indices\n",
    "    # loop over all possible combinations of start and end indices and find the one with the maximum overlap inside\n",
    "    event_inner_cut=event_text.split(' ')[1:-1]\n",
    "    start_ind=-1\n",
    "    end_ind=-1\n",
    "    best_ss_cnt=[]\n",
    "    inner_match_cnt=0\n",
    "    for ss_cut, start_inds, end_inds in match_res:\n",
    "        for s in start_inds:\n",
    "            for e in end_inds:\n",
    "                if s<e:\n",
    "                    cnt=0\n",
    "                    for _x in event_inner_cut:\n",
    "                        if _x in ss_cut[s+1:e]:\n",
    "                            cnt+=1\n",
    "                    if cnt>=inner_match_cnt:\n",
    "                        inner_match_cnt=cnt\n",
    "                        start_ind=s\n",
    "                        end_ind=e\n",
    "                        best_ss_cnt=ss_cut\n",
    "\n",
    "    event_raw_text=' '.join(best_ss_cnt[start_ind:end_ind+1])\n",
    "\n",
    "    if len(event_raw_text)>0:\n",
    "        event_processed.append((text_id, event, event_raw_text, ' '.join(best_ss_cnt), sent))\n",
    "    if len(event_raw_text)==0:\n",
    "        event_unprocessed.append((text_id, event,'','', sent))\n",
    "\n",
    "\n",
    "# tracking\n",
    "print(\"Total events: %d, processed events: %d, ratio: %.2f%%\"%(len(event_sent_list), len(event_processed), 100*len(event_processed)/len(event_sent_list)))\n",
    "\n",
    "event_processed_map={}\n",
    "\n",
    "for text_id, event, event_raw_text, sub_sent, sent in event_processed:\n",
    "    if text_id not in event_processed_map:\n",
    "        event_processed_map[text_id]={}\n",
    "    event_processed_map[text_id][event.__repr__()]=[event_raw_text, sub_sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81dbc1c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Blink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f5d63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 4.Blink\n",
    "\n",
    "belief = Belief(belief_setting)\n",
    "belief.load_belief()\n",
    "belief.revise_belief()\n",
    "\n",
    "aser_events={text_id: aser_list}\n",
    "res = Engine.aser_process(aser_events, belief, event_processed_map, aser_setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f7a89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82a5af",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 5.Render\n",
    "\n",
    "# restore[text_id]\n",
    "# aser[text_id]['sentences']\n",
    "\n",
    "event_texts=', '.join([xx.__repr__() for x in aser_events[text_id] for xx in x])\n",
    "print(event_texts)\n",
    "print('\\n')\n",
    "sentence_texts='. '.join(sentences)+'.'\n",
    "print(sentence_texts)\n",
    "nt,status=render.render(res[text_id]['mapper'],only_active=True)\n",
    "nt.show('_.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}